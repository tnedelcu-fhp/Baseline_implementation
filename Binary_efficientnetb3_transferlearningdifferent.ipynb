{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def append_ext(fn):\n",
    "    return fn+\".jpg\"\n",
    "\n",
    "traindf=pd.read_csv('D:\\\\UNI\\\\5º Ano - 2º Semestre - 2020-2021 - TESE\\\\Dataset\\\\ISIC-2017_Training_Part3_GroundTruth.csv',dtype=str)\n",
    "testdf=pd.read_csv('D:\\\\UNI\\\\5º Ano - 2º Semestre - 2020-2021 - TESE\\\\Dataset\\\\ISIC-2017_Test_v2_Part3_GroundTruth.csv',dtype=str)\n",
    "traindf['image_id']=traindf['image_id'].apply(append_ext)\n",
    "testdf['image_id']=testdf['image_id'].apply(append_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a label column\n",
    "label=[0]*traindf.shape[0]\n",
    "for i in range(traindf.shape[0]):\n",
    "    if traindf['melanoma'][i] == '1.0':\n",
    "        label[i]='1'\n",
    "    else:\n",
    "        label[i]='0'\n",
    "traindf['label']=label    \n",
    "\n",
    "label=[0]*testdf.shape[0]\n",
    "for i in range(testdf.shape[0]):\n",
    "    if testdf['melanoma'][i] == '1.0':\n",
    "        label[i]='1'\n",
    "    else:\n",
    "        label[i]='0'\n",
    "testdf['label']=label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = traindf.loc[:,'image_id']\n",
    "y = traindf.loc[:,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_x, val_x, train_y, val_y = train_test_split(X, y, \n",
    "                                                  test_size = 0.25, \n",
    "                                                  random_state = 27, \n",
    "                                                  stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(columns=['image_id','label'])\n",
    "df_train['image_id'] = train_x\n",
    "df_train['label'] = train_y\n",
    "\n",
    "df_val= pd.DataFrame(columns=['image_id','label'])\n",
    "df_val['image_id'] = val_x\n",
    "df_val['label'] = val_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1220\n",
       "1     280\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index          image_id label\n",
      "0      1864  ISIC_0014658.jpg     0\n",
      "0       387  ISIC_0000482.jpg     1\n",
      "1       689  ISIC_0010016.jpg     1\n",
      "1      1324  ISIC_0012986.jpg     0\n",
      "2      1078  ISIC_0012182.jpg     0\n",
      "...     ...               ...   ...\n",
      "1217   1055  ISIC_0012102.jpg     0\n",
      "1218   1361  ISIC_0013079.jpg     1\n",
      "1218    658  ISIC_0009963.jpg     0\n",
      "1219   1996  ISIC_0015233.jpg     0\n",
      "1219   1031  ISIC_0011348.jpg     1\n",
      "\n",
      "[2440 rows x 3 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1220\n",
       "1    1220\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "non_melanoma = df_train[df_train['label']=='0']\n",
    "melanoma = df_train[df_train['label']=='1']\n",
    "\n",
    "# upsample minority -> some samples of melanoma will be duplicated\n",
    "melanoma_upsampled = resample(melanoma,\n",
    "                          replace=True, # sample with replacement\n",
    "                          n_samples=len(non_melanoma), # match number in majority class\n",
    "                          random_state=27) # reproducible results\n",
    "\n",
    "\n",
    "# combine majority and upsampled minority alternately\n",
    "# by reseting indexes, both dataframes now start at 0, 1, 2, etc. and are then sorted\n",
    "df_train_upsampled = pd.concat([non_melanoma.reset_index(), melanoma_upsampled.reset_index()]).sort_index()\n",
    "print(df_train_upsampled)\n",
    "\n",
    "\n",
    "df_train_upsampled['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment according to the architecture being used\n",
    "# IMG_SIZE = 224 #B0\n",
    "# IMG_SIZE = 240 #B1\n",
    "# IMG_SIZE = 260 #B2\n",
    "IMG_SIZE = 300 #B3\n",
    "# IMG_SIZE = 380 #B4\n",
    "# IMG_SIZE = 456 #B5\n",
    "# IMG_SIZE = 528 #B6\n",
    "# IMG_SIZE = 600 #B7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2440 validated image filenames belonging to 2 classes.\n",
      "Found 500 validated image filenames belonging to 2 classes.\n",
      "Found 600 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "train_datagen=ImageDataGenerator(rotation_range=5,  # rotation\n",
    "                                 width_shift_range=0.2,  # horizontal shift\n",
    "                                 zoom_range=0.2,  # zoom\n",
    "                                 horizontal_flip=True,  # horizontal flip\n",
    "                                 brightness_range=[0.2,0.8] # brightness\n",
    "                                 #rescale=1./255.\n",
    "                                )  \n",
    "\n",
    "train_generator=train_datagen.flow_from_dataframe(dataframe=df_train_upsampled,\n",
    "                                            directory='D:\\\\UNI\\\\5º Ano - 2º Semestre - 2020-2021 - TESE\\\\Dataset\\\\ISIC-2017_Training_Data\\\\',\n",
    "                                            x_col='image_id',\n",
    "                                            y_col='label',\n",
    "                                            batch_size=16,\n",
    "                                            seed=42,\n",
    "                                            shuffle=False,\n",
    "                                            class_mode='binary',\n",
    "                                            target_size=(IMG_SIZE,IMG_SIZE)\n",
    "                                           )\n",
    "\n",
    "valid_datagen=ImageDataGenerator()#rescale=1./255.)\n",
    "valid_generator=valid_datagen.flow_from_dataframe(dataframe=df_val,\n",
    "                                            directory='D:\\\\UNI\\\\5º Ano - 2º Semestre - 2020-2021 - TESE\\\\Dataset\\\\ISIC-2017_Training_Data\\\\',\n",
    "                                            x_col='image_id',\n",
    "                                            y_col='label',\n",
    "                                            batch_size=16,\n",
    "                                            seed=42,\n",
    "                                            shuffle=False,\n",
    "                                            class_mode='binary',\n",
    "                                            target_size=(IMG_SIZE,IMG_SIZE)\n",
    "                                           )\n",
    "\n",
    "test_datagen=ImageDataGenerator()#rescale=1./255.)\n",
    "test_generator=test_datagen.flow_from_dataframe(dataframe=testdf,\n",
    "                                                directory='D:\\\\UNI\\\\5º Ano - 2º Semestre - 2020-2021 - TESE\\\\Dataset\\\\ISIC-2017_Test_v2_Data\\\\',\n",
    "                                                x_col='image_id',\n",
    "                                                y_col=None,\n",
    "                                                batch_size=30,\n",
    "                                                seed=40,\n",
    "                                                shuffle=False,\n",
    "                                                class_mode=None,\n",
    "                                                target_size=(IMG_SIZE,IMG_SIZE)\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "# Create the base model from the pre-trained model EfficientNet\n",
    "base_model = EfficientNetB3(include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'top_model_weights_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-f7e8d84321bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;31m# classifier, including the top classifier,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# in order to successfully do fine-tuning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mtop_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_model_weights_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# add the model on top of the convolutional base\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'top_model_weights_path' is not defined"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "\n",
    "IMG_SIZE=300\n",
    "top_model = Sequential()\n",
    "top_model.add(Flatten(input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "top_model.add(Dropout(0.5))\n",
    "top_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# note that it is necessary to start with a fully-trained\n",
    "# classifier, including the top classifier,\n",
    "# in order to successfully do fine-tuning\n",
    "top_model.load_weights(top_model_weights_path)\n",
    "\n",
    "# add the model on top of the convolutional base\n",
    "base_model.add(top_model)\n",
    "\n",
    "# set the first 25 layers (up to the last conv block)\n",
    "# to non-trainable (weights will not be updated)\n",
    "for layer in base_model.layers[:384]:\n",
    "    layer.trainable = False\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "base_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_2 True\n",
      "efficientnetb3 False\n",
      "global_average_pooling2d True\n",
      "batch_normalization True\n",
      "top_dropout True\n",
      "pred True\n"
     ]
    }
   ],
   "source": [
    "for l in model.layers:\n",
    "    print(l.name, l.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 132s 4s/step - loss: 0.7253 - accuracy: 0.1959\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7263209223747253, 0.1854838728904724]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#how this model performs on this data before fitting\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "model.evaluate(valid_generator,\n",
    "               steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "153/153 [==============================] - 815s 5s/step - loss: 0.7580 - accuracy: 0.4992 - val_loss: 0.6692 - val_accuracy: 0.8120\n",
      "Epoch 2/15\n",
      "153/153 [==============================] - 845s 6s/step - loss: 0.7475 - accuracy: 0.5086 - val_loss: 0.6869 - val_accuracy: 0.8120\n",
      "Epoch 3/15\n",
      " 74/153 [=============>................] - ETA: 6:00 - loss: 0.7370 - accuracy: 0.4975"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-58a80139425a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mSTEP_SIZE_TRAIN\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m//\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m model.fit(train_generator,\n\u001b[0m\u001b[0;32m      4\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rafag\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1098\u001b[0m                 _r=1):\n\u001b[0;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1100\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1101\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rafag\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rafag\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rafag\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rafag\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\rafag\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rafag\\anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "\n",
    "model.fit(train_generator,\n",
    "          epochs=15,\n",
    "          validation_data=valid_generator,\n",
    "          verbose=1\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how this model performs after fitting\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "model.evaluate(valid_generator,\n",
    "               steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "pred=model.predict(test_generator,\n",
    "                   steps=STEP_SIZE_TEST,\n",
    "                   verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_pred=np.where(pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "x = test_generator.next() #this unpacks the ImageDataGenerator which is composed by x(image) and y(label). In the case of test, there are not labels\n",
    "for i in range(5):\n",
    "    image = x[i]\n",
    "    plt.title('Predicted Label: ' + str(labels_pred[i]))\n",
    "    plt.imshow(image.astype(np.uint8))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.accuracy_score(testdf['label'].astype(int).to_numpy(), labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix=sklearn.metrics.confusion_matrix(testdf['label'].astype(int).to_numpy(), labels_pred)\n",
    "\n",
    "print('Confusion Matrix: \\n' + str(confusion_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "fpr, tpr, threshold = roc_curve(testdf['label'].astype(int).to_numpy(),labels_pred)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "print('AUC Score: ' + str(roc_auc))\n",
    "\n",
    "# plot the roc curve for the model\n",
    "plt.plot(fpr, tpr, linestyle='-', label='EfficientNet B3')\n",
    "# axis labels\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# show the legend\n",
    "plt.legend()\n",
    "# show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jac=sklearn.metrics.jaccard_score(testdf['label'].astype(int).to_numpy(), labels_pred)\n",
    "print('Jaccard Score: ' + str(jac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"EfficientNetB3_sigmoid.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# load model\n",
    "#model = tf.keras.models.load_model('EfficientNetB3_sigmoid.h5')\n",
    "#model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
